---
Author:
tags:
  - мой_проект
date:
url:
imageNameKey:
---
# **Архитектура MCP-сервера для GraphRAG: Глубокая интеграция локальных графовых и векторных баз данных с агентным управлением**

## **1\. Введение и постановка задачи**

Современная разработка программного обеспечения переживает смену парадигм, вызванную интеграцией больших языковых моделей (LLM) в процессы написания, отладки и рефакторинга кода. Традиционные подходы к семантическому поиску по кодовым базам, основанные на стандартной архитектуре Retrieval-Augmented Generation (RAG), демонстрируют существенные ограничения при работе со сложноструктурированными данными, каковыми являются исходные тексты программ. Код — это не просто последовательность токенов; это строгая иерархическая и сетевая структура, насыщенная зависимостями, наследованием и перекрестными ссылками. Игнорирование этой структуры при векторизации приводит к потере контекста, галлюцинациям моделей и неспособности решать задачи, требующие многоходовых рассуждений (multi-hop reasoning).  
Данный отчет представляет собой исчерпывающее техническое исследование и архитектурную спецификацию для создания сервера, реализующего протокол Model Context Protocol (MCP) для системы GraphRAG (Graph-based Retrieval-Augmented Generation). Ключевой особенностью предлагаемой архитектуры является **гибридный подход**, объединяющий локальные графовые базы данных (для структурного анализа) и векторные хранилища (для семантического поиска) под управлением автономных LLM-агентов. Особое внимание уделяется требованиям приватности (локальное исполнение через Ollama), инкрементальности обновлений (интеграция с Git) и стандартизации интерфейсов через MCP, что позволяет отделить логику хранения данных от логики их обработки агентом.  
Целью разработки является создание системы, способной отвечать на сложные вопросы о кодовой базе (например, «Как изменение в этом классе повлияет на микросервисы, использующие его API?»), опираясь не только на текстовое сходство, но и на точный граф вызовов и зависимостей, при этом сохраняя все данные внутри периметра разработчика.

## ---

**2\. Теоретические основы и обоснование выбора технологий**

### **2.1 Эволюция RAG: От наивного поиска к GraphRAG в программной инженерии**

Классический RAG ("Naive RAG") работает по принципу разбиения документов на фрагменты (чанки), вычисления их векторных представлений (эмбеддингов) и поиска ближайших соседей по косинусному расстоянию. В контексте документации на естественном языке этот подход показывает высокую эффективность. Однако применительно к программному коду он сталкивается с фундаментальными проблемами. Код обладает высокой степенью нелокальности: определение функции может находиться в одном файле, ее вызов — в другом, а интерфейс, который она реализует — в третьем. Векторный поиск часто находит фрагменты, семантически похожие на запрос (например, функции с именем processPayment), но не способен проследить цепочку выполнения, которая привела к вызову этой функции.  
GraphRAG решает эту проблему путем построения графа знаний (Code Knowledge Graph — CKG), где узлами выступают сущности кода (классы, методы, переменные), а ребрами — отношения между ними (вызовы, импорты, наследование). Гибридный подход, комбинирующий векторный поиск для нахождения «точки входа» и графовый обход для сбора контекста («окрестности»), позволяет моделировать мышление опытного разработчика, который при анализе кода перемещается по ссылкам и иерархиям.  
Исследования показывают, что использование GraphRAG значительно повышает точность ответов на вопросы, требующие глобального понимания структуры проекта, по сравнению с чистым векторным поиском. В частности, интеграция графов позволяет реализовать паттерн «Local-to-Global», при котором система может отвечать как на узкие вопросы о реализации конкретного метода, так и на широкие вопросы об архитектуре модуля, используя кластеризацию узлов графа.

### **2.2 Протокол Model Context Protocol (MCP): Стандартизация инструментов**

Выбор протокола Model Context Protocol (MCP) в качестве интерфейсного слоя продиктован необходимостью стандартизации взаимодействия между LLM-агентами (клиентами) и источниками данных (серверами). В традиционных архитектурах инструменты жестко «зашиты» в код агента, что делает систему монолитной и сложной для масштабирования. MCP предлагает четкое разделение ответственности:

* **MCP-сервер** предоставляет *возможности* (Capabilities): инструменты (Tools), ресурсы (Resources) и промпты (Prompts). Он не принимает решений, а лишь исполняет запросы.  
* **MCP-клиент (Агент)** содержит *интеллект*. Он определяет, какой инструмент вызвать, анализирует результаты и строит цепочки рассуждений.

Такая архитектура позволяет использовать разработанный сервер GraphRAG с любым MCP-совместимым клиентом — будь то Claude Desktop, IDE-плагин или автономный CLI-агент, без необходимости модификации серверной части. Кроме того, поддержка протоколом асинхронных уведомлений (Notifications) критически важна для длительных процессов, таких как индексация репозитория.

### **2.3 Выбор стека локальных баз данных**

Требование локальной работы и высокой производительности накладывает жесткие ограничения на выбор СУБД.

#### **Графовая база данных: Memgraph vs. Neo4j**

Для хранения графа кода рассматривались Neo4j и Memgraph. Neo4j является индустриальным стандартом с богатой экосистемой, однако его архитектура, основанная на JVM (Java Virtual Machine), потребляет значительные ресурсы памяти и имеет высокое время холодного старта, что может быть критично для локального инструмента разработчика.  
Memgraph, напротив, реализован на C++ и работает в режиме in-memory, обеспечивая существенно меньшую латентность при выполнении сложных запросов на обход графа (например, поиск путей вызовов большой глубины). Тесты производительности демонстрируют, что Memgraph может выполнять запросы на расширение контекста (expansion queries) в десятки раз быстрее аналогов при меньшем потреблении оперативной памяти, что делает его предпочтительным выбором для локального MCP-сервера. Поддержка языка запросов Cypher обеспечивает совместимость с существующими инструментами и практиками.

#### **Векторная база данных: Qdrant**

В качестве векторного хранилища выбран Qdrant. Написанный на Rust, он обеспечивает высокую производительность и стабильность. Ключевым преимуществом Qdrant для данной задачи является мощная система фильтрации по полезной нагрузке (payload filtering). Это позволяет выполнять гибридные запросы, например: «Найти функции, похожие на 'auth validation', но только внутри файлов, измененных в последнем коммите Git». Qdrant также эффективно работает в Docker-контейнерах с ограниченными ресурсами.

## ---

**3\. Архитектура системы: Компонентный обзор**

Архитектура MCP-сервера для GraphRAG строится по многослойному принципу, обеспечивая слабую связность компонентов и возможность независимого обновления модулей.

### **3.1 Слой интерфейса (MCP Interface Layer)**

Этот слой отвечает за реализацию протокола JSON-RPC 2.0. Он экспонирует функциональность системы в виде набора примитивов MCP:

* **Инструменты (Tools)**: Функции, которые может вызывать агент (например, search\_semantic, query\_graph, get\_file\_diff).  
* **Ресурсы (Resources)**: Прямой доступ к файловой структуре проекта и содержимому файлов через URI схемы code://.  
* **Уведомления (Notifications)**: Каналы для отправки статусов индексации и оповещений об изменениях в коде.

### **3.2 Слой оркестрации и логики (Orchestration Layer)**

Здесь происходит «магия» преобразования запросов агента в конкретные операции с базами данных. Этот слой управляет потоками данных, синхронизацией между графовым и векторным индексами и обработкой очередей задач. Важнейшей частью является менеджер сессий, который обеспечивает изоляцию контекста при работе с несколькими репозиториями одновременно.

### **3.3 Слой обработки данных (Ingestion & Processing Layer)**

Этот слой отвечает за преобразование исходного кода в структурированные данные. Он включает в себя:

* **Парсер Tree-sitter**: Генерирует абстрактные синтаксические деревья (AST) для поддерживаемых языков (Python, JavaScript, Java, Rust и др.).  
* **Git-анализатор**: Вычисляет диффы, определяет авторов изменений и временные метки.  
* **Сервис эмбеддингов**: Абстракция над провайдерами векторизации (Ollama для локальной работы, OpenAI/Cohere для облачной), обеспечивающая генерацию векторов для текстовых чанков.

### **3.4 Слой хранения (Storage Layer)**

Физическое хранение данных осуществляется в Docker-контейнерах Memgraph и Qdrant, управляемых через docker-compose. Это обеспечивает простоту развертывания и чистоту хост-системы.

## ---

**4\. Проектирование схемы данных Графа Знаний (Code Knowledge Graph)**

Эффективность GraphRAG напрямую зависит от качества онтологии — схемы данных, описывающей сущности кода и связи между ними. Схема должна быть достаточно детальной для глубокого анализа, но не перегруженной, чтобы избежать комбинаторного взрыва при обходе.

### **4.1 Узлы (Nodes)**

Мы определяем следующий набор узлов, покрывающий основные аспекты программной архитектуры:

| Тип узла | Описание | Основные свойства |
| :---- | :---- | :---- |
| **File** | Файл исходного кода. | path (уникальный ID), language, loc (строк кода), last\_modified, git\_hash |
| **Directory** | Директория файловой системы. | path |
| **Module** | Логический модуль или пакет (namespace). | name, full\_path |
| **Class** | Класс, структура или интерфейс. | name, docstring, modifiers (public/private), start\_line, end\_line |
| **Function** | Метод, функция или лямбда-выражение. | name, signature, return\_type, docstring, complexity (цикломатическая сложность), start\_line, end\_line, content\_hash |
| **Variable** | Глобальная переменная, поле класса или аргумент. | name, type, default\_value |
| **Chunk** | Текстовый фрагмент для векторного поиска. | text, embedding\_id (ссылка на Qdrant), token\_count |
| **Commit** | Коммит в Git. | hash, message, author, date |

### **4.2 Связи (Relationships)**

Связи в графе делятся на три категории: структурные, семантические и исторические.

#### **Структурные связи (иерархия и принадлежность):**

* (:Directory)--\>(:File)  
* (:File)--\>(:Class)  
* (:Class)--\>(:Function)  
* (:Function)--\>(:Variable)

#### **Семантические связи (поток управления и данных):**

* (:Function)--\>(:Function): Самая важная связь для построения графов вызовов (Call Graphs).  
* (:Class)--\>(:Class): Описывает иерархию наследования.  
* (:File)--\>(:Module): Зависимости между файлами.  
* (:Chunk)--\>(:Function): Связь «многие-ко-многим», соединяющая векторное представление с его структурным прототипом. Это мост между графом и векторной БД.

#### **Исторические связи (Git):**

* (:Commit)--\>(:File): Позволяет отвечать на вопросы типа «Какие файлы менялись вместе в рамках одной задачи?».  
* (:Commit)--\>(:Commit): История изменений.

### **4.3 Стратегия связывания (Linking Strategy)**

При наполнении базы данных критически важно корректно разрешать ссылки. Например, если функция A вызывает функцию B, парсер видит только имя B. Система должна выполнить разрешение имен (name resolution), чтобы найти конкретный узел Function с именем B, учитывая область видимости и импорты. Для динамических языков (Python, JS) это делается эвристически, для статических (Java, C\#) — с большей точностью. Ошибки разрешения помечаются специальным флагом unresolved: true на ребре, что позволяет агенту понимать степень достоверности графа.

## ---

**5\. Подсистема инкрементальной индексации и интеграции с Git**

Одной из главных проблем RAG для кода является устаревание данных. Полная переиндексация репозитория при каждом сохранении файла недопустима из\-за высоких вычислительных затрат на генерацию эмбеддингов. Мы предлагаем алгоритм дифференциальной индексации.

### **5.1 Алгоритм обработки изменений (Diff Processing)**

Система работает в цикле обработки событий (Event Loop), реагируя на изменения файловой системы или HEAD git-репозитория.

1. **Обнаружение изменений**: Используется команда git diff \--name-status для получения списка измененных файлов.  
   * **Добавленные файлы (A)**: Отправляются в очередь на полный парсинг.  
   * **Удаленные файлы (D)**: Выполняется Cypher-запрос MATCH (f:File {path: $path}) DETACH DELETE f, удаляющий файл и все связанные с ним узлы (функции, классы), а также удаление векторов из Qdrant по ID.  
   * **Модифицированные файлы (M)**: Запускается процедура гранулярного обновления.  
2. **Гранулярное обновление через AST**:  
   Простого переписывания файла недостаточно, так как это дорого. Мы используем Tree-sitter для частичного обновления.  
   * Вычисляется хеш-сумма контента каждой функции в новой версии файла.  
   * Сравнивается с хешем, сохраненным в свойстве content\_hash узла Function в графе.  
   * Если хеш совпадает, узел и его эмбеддинг не обновляются (даже если файл был сохранен).  
   * Если хеш изменился, генерируется новый эмбеддинг, обновляются свойства узла, и перестраиваются исходящие ребра \`\`.

### **5.2 Обработка "Зомби-связей"**

При удалении или переименовании функции могут остаться "висячие" ребра \`\` от других функций, которые её вызывали. Система запускает фоновый процесс "Graph Garbage Collector", который помечает такие ребра как broken или пытается перепривязать их к новым узлам, если обнаруживается переименование (через анализ схожести сигнатур и метрик Git git diff \-M для детекции переименований).

## ---

**6\. Гибкая генерация эмбеддингов: Ollama и API**

Для удовлетворения требования гибкости (работа локально или через облако) архитектура реализует паттерн «Адаптер» для провайдеров эмбеддингов.

### **6.1 Абстракция провайдера**

Определяется базовый класс EmbeddingProvider с методом embed\_documents(texts: List\[str\]) \-\> List\[List\[float\]\].

#### **Реализация Ollama (Локальная)**

Использует библиотеку llama-index-embeddings-ollama или прямые HTTP-запросы к API Ollama.

* **Модели**: Рекомендуется использование nomic-embed-text (v1.5) или mxbai-embed-large. Эти модели оптимизированы для задач поиска (retrieval) и имеют высокую размерность контекстного окна, что важно для кода.  
* **Управление ресурсами**: Локальный запуск требует контроля памяти. MCP-сервер реализует семафор, ограничивающий количество параллельных запросов к Ollama, чтобы не заблокировать работу основного LLM-агента, если они делят один GPU.

#### **Реализация Remote API**

Поддержка OpenAI (text-embedding-3-small) или Cohere (специализированные модели для RAG). Используется, когда локальные ресурсы ограничены или требуется максимальное качество.

### **6.2 Проблема размерности векторов**

При переключении между провайдерами (например, с OpenAI 1536d на Nomic 768d) структура векторной коллекции становится невалидной. Сервер отслеживает метаданные текущей коллекции в Qdrant. При обнаружении несовпадения размерности сервер автоматически предлагает пользователю (через уведомление MCP) выполнить переиндексацию или создает новую коллекцию (namespace), сохраняя старую.

## ---

**7\. Реализация MCP-сервера: Инструменты и Логика**

Ядро системы — это реализация спецификации MCP. Мы используем Python SDK (fastmcp или mcp) для декларативного определения инструментов.

### **7.1 Определение инструментов (Tool Definitions)**

Инструменты должны быть атомарными, чтобы агент мог гибко комбинировать их.

#### **Инструмент 1: search\_code\_semantic**

* **Назначение**: Поиск по смыслу (векторный).  
* **Аргументы**:  
  * query (string): Поисковый запрос на естественном языке.  
  * k (int): Количество результатов.  
  * scope (optional string): Ограничение по пути (например, "src/auth").  
* **Логика**: Вызывает эмбеддер, получает вектор запроса, выполняет поиск в Qdrant с фильтрацией по метаданным path (если указан scope). Возвращает сниппеты кода.

#### **Инструмент 2: query\_graph\_cypher**

* **Назначение**: Прямое выполнение Cypher-запросов для сложного структурного анализа.  
* **Аргументы**:  
  * query (string): Cypher-запрос.  
* **Безопасность**: Реализуется валидатор (Sanitizer), блокирующий операции записи (CREATE, DELETE, SET), разрешая только MATCH и RETURN. Это критически важно для безопасности, чтобы агент случайно не повредил базу знаний.

#### **Инструмент 3: get\_call\_hierarchy**

* **Назначение**: Получение цепочки вызовов для функции.  
* **Аргументы**:  
  * function\_name (string).  
  * depth (int): Глубина поиска.  
  * direction (enum): "upstream" (кто вызывает) или "downstream" (кого вызывает).  
* **Логика**: Выполняет оптимизированный Cypher-запрос (например, MATCH path=(f:Function {name: $name})\<--(caller) RETURN path). Возвращает JSON-представление подграфа.

#### **Инструмент 4: get\_git\_context**

* **Назначение**: Анализ истории изменений.  
* **Аргументы**:  
  * file\_path (string).  
  * since\_commit (string).  
* **Логика**: Возвращает список авторов и сообщений коммитов, затрагивающих данный файл, помогая агенту понять, *почему* код написан именно так.

### **7.2 Асинхронные уведомления (Notifications)**

Поскольку индексация большого проекта может занимать минуты, сервер использует механизм уведомлений MCP для информирования пользователя.

* notifications/indexing/started: Отправляется при запуске парсера.  
* notifications/indexing/progress: Отправляется каждые N файлов ({processed: 50, total: 1200}).  
* notifications/indexing/finished: Сигнализирует агенту, что данные актуальны и можно начинать сложные запросы.

## ---

**8\. Управление логикой: LLM-Агент и Оркестрация**

В предложенной архитектуре сервер предоставляет *инструменты*, а логика рассуждений (Reasoning) делегируется Агенту. Для реализации агента наиболее эффективным является использование фреймворка **LangGraph** (по сравнению с линейными цепочками LangChain), так как он нативно поддерживает циклические графы выполнения и сохранение состояния (stateful execution), что необходимо для итеративного поиска.

### **8.1 Паттерн Router Query Engine**

Агент реализует логику маршрутизации запросов (Routing) на основе намерений пользователя.

| Намерение пользователя | Маршрут | Инструменты |
| :---- | :---- | :---- |
| «Как работает авторизация?» | Семантический поиск | search\_code\_semantic |
| «Где используется класс User?» | Структурный поиск | query\_graph\_cypher (Text-to-Cypher) |
| «Кто сломал билд в пятницу?» | Исторический анализ | get\_git\_context |
| «Почему возникает ошибка NullPointer в модуле X?» | Гибридный анализ (ReAct) | Комбинация всех инструментов в цикле |

### **8.2 Text-to-Cypher: Генерация запросов**

Для выполнения структурных запросов агент должен уметь переводить естественный язык в Cypher. Чтобы повысить точность:

1. Сервер предоставляет агенту схему графа (список узлов и ребер) в системном промпте или через специальный ресурс resource://schema.  
2. Агент использует few-shot prompting (примеры запросов) для генерации корректного Cypher.  
3. Если запрос возвращает синтаксическую ошибку, агент получает её текст, исправляет запрос и пробует снова (Self-Correction Loop).

### **8.3 Паттерн Local-to-Global (Summarization)**

Для ответов на высокоуровневые вопросы («Опиши архитектуру проекта») агент использует стратегию Summarization. Он запрашивает у сервера список модулей верхнего уровня, затем для каждого модуля запрашивает сводку (хранящуюся в узлах Concept), и синтезирует общий ответ. Это позволяет преодолеть ограничения контекстного окна, не загружая в промпт весь код целиком.

## ---

**9\. Руководство по реализации (Implementation Guide)**

Ниже приведен план реализации MVP на языке Python.

### **9.1 Стек технологий**

* **Язык**: Python 3.10+ (обязательно для современной асинхронности).  
* **MCP SDK**: mcp (официальный SDK) или fastmcp (обертка для быстрого старта).  
* **Graph Driver**: gqlalchemy (ORM для Memgraph) или neo4j (официальный драйвер).  
* **Vector Driver**: qdrant-client.  
* **Parsing**: tree-sitter, tree-sitter-languages (пакет с бинарниками грамматик).  
* **LLM Integration**: llama-index (для удобной работы с чанками и эмбеддингами).

### **9.2 Структура проекта**

graphrag-mcp/  
├── src/  
│ ├── server.py \# Точка входа FastMCP  
│ ├── config.py \# Настройки (ENV variables)  
│ ├── database/  
│ │ ├── graph.py \# Подключение к Memgraph  
│ │ └── vector.py \# Подключение к Qdrant  
│ ├── ingestion/  
│ │ ├── parser.py \# Логика Tree-sitter  
│ │ ├── git\_watcher.py \# Мониторинг изменений  
│ │ └── processor.py \# Оркестратор индексации  
│ └── tools/ \# Реализация функций инструментов  
│ ├── search.py  
│ └── analytics.py  
├── docker-compose.yml \# Memgraph, Qdrant, Ollama  
└── pyproject.toml \# Зависимости

### **9.3 Пример реализации инструмента (Python)**

Ниже приведен пример кода для инструмента гибридного поиска, реализующего логику объединения результатов.

```Python

from mcp.server.fastmcp import FastMCP  
from src.database.vector import VectorDB  
from src.database.graph import GraphDB

mcp \= FastMCP("GraphRAG-Code")  
vector\_db \= VectorDB()  
graph\_db \= GraphDB()

@mcp.tool()  
async def hybrid\_search(query: str, hops: int \= 1\) \-\> str:  
    """  
    Выполняет гибридный поиск: находит релевантный код по смыслу,  
    а затем расширяет контекст через граф зависимостей.  
    Args:  
        query: Вопрос пользователя.  
        hops: Количество шагов расширения графа (по умолчанию 1).  
    """  
    \# 1\. Векторный поиск  
    vector\_results \= await vector\_db.search(query, limit=5)  
    if not vector\_results:  
        return "Ничего не найдено."

    \# 2\. Сбор ID найденных функций  
    function\_ids \= \[res.payload\['function\_id'\] for res in vector\_results\]  
      
    \# 3\. Расширение графа (Graph Expansion)  
    \# Находим соседей (кто вызывает и кого вызывают эти функции)  
    cypher \= f"""  
    MATCH (center:Function)  
    WHERE center.uid IN $ids  
    MATCH (center)--(neighbor:Function)  
    RETURN center.name, type(r), neighbor.name, neighbor.docstring  
    """  
    graph\_context \= await graph\_db.execute(cypher, parameters={'ids': function\_ids})  
      
    \# 4\. Форматирование ответа  
    response \= "Found Semantic Matches:\\n"  
    for res in vector\_results:  
        response \+= f"- {res.payload\['name'\]} (Score: {res.score:.2f})\\n"  
      
    response \+= "\\nStructural Context:\\n"  
    for row in graph\_context:  
        response \+= f"- {row\['center.name'\]} \--\[{row\['type(r)'\]}\]--\> {row\['neighbor.name'\]}\\n"  
          
    return response
```




## ---

**10\. Аспекты производительности и масштабируемости**

Для обеспечения плавной работы на локальных машинах (например, MacBook M-series или PC с NVIDIA GPU) необходимо применять ряд оптимизаций.

### **10.1 Пакетная обработка (Batching)**

При первичной индексации отправка каждого чанка в Ollama по одному приведет к огромным накладным расходам на HTTP/IPC. Реализуется буферизация: чанки накапливаются в пакеты по 32-64 элемента и отправляются на эмбеддинг одной операцией. Memgraph также поддерживает транзакционную загрузку: узлы и ребра должны загружаться пачками (например, по 1000 сущностей) с использованием LOAD CSV или пакетных вставок драйвера.

### **10.2 Кэширование (Caching)**

Реализуется двухуровневое кэширование:

1. **Semantic Cache**: Кэш эмбеддингов (Redis или локальный DiskCache). Ключом является хеш текста чанка \+ имя модели. Это предотвращает повторную генерацию векторов для неизменного кода.  
2. **Query Cache**: Результаты тяжелых Cypher-запросов (например, построение полного графа вызовов модуля) кэшируются с коротким TTL, чтобы агент мог быстро переспрашивать уточняющие вопросы.

### **10.3 Ограничение глубины рекурсии**

В графах вызовов программного кода часто встречаются циклы (рекурсия) или сверхплотные узлы (utility-классы, которые используют все). Инструменты обхода графа должны иметь жесткие ограничения (hard limits) на глубину (например, макс. 3 прыжка) и количество возвращаемых узлов (limit 100), чтобы не переполнить контекстное окно LLM мусором.

## ---

**11\. Заключение**

Предложенная архитектура MCP-сервера для GraphRAG представляет собой сбалансированное решение, объединяющее мощь современных графовых алгоритмов с гибкостью генеративного ИИ. Интеграция Memgraph и Qdrant обеспечивает необходимую производительность для локального анализа, а использование протокола MCP гарантирует, что система останется совместимой с будущими поколениями ИИ-агентов.  
Переход от текстового представления кода к графовому открывает возможности для создания качественно новых инструментов разработки: от автоматизированного архитектурного аудита до интеллектуальных агентов, способных проводить глубокий рефакторинг, понимая скрытые зависимости, недоступные обычному текстовому поиску. Реализация данной архитектуры позволит разработчикам получить "второго пилота", который не просто угадывает следующий токен, а действительно понимает структуру и логику создаваемого программного обеспечения.

## ---

**Список таблиц данных**

### **Таблица 1\. Сравнение графовых баз данных для локального MCP-сервера**

| Характеристика | Memgraph | Neo4j Community | Обоснование выбора Memgraph |
| :---- | :---- | :---- | :---- |
| **Язык реализации** | C++ | Java (JVM) | C++ обеспечивает меньшие накладные расходы и быстрый старт. |
| **Хранение данных** | In-Memory (с персистенцией на диск) | Native Graph Store (Disk-based) | In-Memory идеален для графов кода (обычно помещаются в RAM) и обеспечивает мгновенный обход. |
| **Латентность (Hop Query)** | \~1 ms | \~27 ms (холодный), \~5 ms (теплый) | Критично для агентных циклов, выполняющих сотни запросов. |
| **Поддержка алгоритмов** | Встроена (MAGE library) | Требует плагинов (GDS Library) | "Из коробки" доступны PageRank, Community Detection. |
| **Лицензия** | Business Source License (BSL) | GPLv3 | Достаточно для внутренней разработки и локальных инструментов. |

### **Таблица 2\. Матрица возможностей маршрутизации (Router Decision Matrix)**

| Тип запроса пользователя | Требуемый ресурс | Инструмент MCP | Пример промпта агента |
| :---- | :---- | :---- | :---- |
| Поиск реализации функционала | Векторная БД | search\_code\_semantic | "Найди код, отвечающий за валидацию email" |
| Анализ влияния изменений | Графовая БД \+ Git | get\_file\_diff \-\> query\_graph | "Какие функции вызывают validate\_email, который был изменен в последнем коммите?" |
| Архитектурный обзор | Графовая БД (Агрегации) | get\_module\_structure | "Покажи диаграмму классов модуля Auth" |
| Отладка ошибки | Гибридный (Вектор \+ Граф) | ReAct Loop | "Почему OrderService возвращает 500 ошибку при пустой корзине?" |

---

*Примечание: Все утверждения в отчете основаны на анализе предоставленных исследовательских материалов, включая документацию по MCP, бенчмарки баз данных и статьи по методологиям GraphRAG.*