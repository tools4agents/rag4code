---
Author:
  - Ширяев Антон
tags:
  - графы_знаний
  - MCP
  - llm_coding_assistant
date: 2025-01-29
url:
imageNameKey:
---
Вот список готовых и популярных MCP-серверов для работы с графами знаний и проведения исследований:

1. Официальные и базовые (Memory & Knowledge)

- **Knowledge Graph Memory (от Anthropic):** Базовая реализация для создания постоянной памяти ИИ. Позволяет модели сохранять сущности и связи между ними в локальном JSON-файле.
- **n-r-w/knowledgegraph-mcp:** Улучшенная версия с поддержкой **PostgreSQL** (вместо простых файлов) и изоляцией данных по проектам. 

2. Специализированные для исследований (Research & GraphRAG)

- **Graphiti (от Zep):** Продвинутый сервер для построения «эпизодических» графов знаний. Он учитывает время появления информации и отлично подходит для анализа динамически меняющихся данных.
- **GraphRAG MCP Server (lyndonkl/graphragmcp):** Специально заточен под архитектуру GraphRAG (Retrieval-Augmented Generation на графах) для глубокого научного рассуждения.
- **GPT Researcher:** Автономный агент для проведения глубоких исследований в сети и локально, генерирующий отчеты с цитатами. 

3. Интеграция с СУБД и внешними базами

- **FalkorDB MCP:** Позволяет подключать графовую базу данных FalkorDB и управлять ею через естественный язык.
- **Neo4j MCP:** Официальная интеграция для работы с одной из самых мощных графовых СУБД в мире.
- **Roam Research / Notion MCP:** Позволяют использовать ваши личные базы заметок как внешний граф знаний.

Выбор между этими тремя инструментами зависит от того, насколько глубоко вы хотите анализировать код и как много данных планируете хранить. В 2026 году эти решения стали стандартом для локальной разработки.

Вот сравнение и пошаговый план:

Сравнение инструментов

|Характеристика|**FalkorDB MCP**|**Neo4j MCP**|**Graphiti (Zep)**|
|---|---|---|---|
|**Скорость**|**Экстремальная** (In-memory)|Высокая|Средняя|
|**Сложность**|Низкая (простой запуск)|Средняя (нужно знать Cypher)|Высокая (требует настройки)|
|**Сильная сторона**|Быстрые ответы на лету|Мощная визуализация и аналитика|**Память во времени** (версионность)|
|**Хранение кода**|Идеально для графа вызовов|Идеально для иерархии классов|Идеально для истории изменений|

---

Как построить Memory Bank (Пошаговый план)

Для локальной работы с кодом Python я рекомендую начать с **FalkorDB**, так как он потребляет меньше ресурсов и работает быстрее всех.

1. Подготовка инфраструктуры (Local)

Запустите базу данных в Docker. Это обеспечит отсутствие лимитов и полную приватность:

bash

```
docker run -p 6379:6379 -it --rm falkordb/falkordb
```

Используйте код с осторожностью.

2. Настройка MCP в вашем клиенте (Claude Desktop или Cursor)

Добавьте сервер в ваш файл конфигурации `mcpConfig.json`:

json

```
{
  "mcpServers": {
    "falkordb": {
      "command": "npx",
      "args": ["-y", "@falkordb/mcp-server"]
    }
  }
}
```

Используйте код с осторожностью.

3. Наполнение Memory Bank (Workflow)

Чтобы построить качественный граф, не пытайтесь загрузить всё сразу. Действуйте итеративно:

- **Этап А: Архитектура документации.**  
    Дайте ИИ прочитать ваши README и технические задания.  
    _Команда ИИ:_ «Проанализируй README.md и создай в графе узлы для основных модулей проекта и их целей».
- **Этап Б: Структура кода.**  
    Загружайте файлы по одному или по папкам.  
    _Команда ИИ:_ «Изучи файл `main.py` и `database.py`. Добавь в граф связи: какие функции вызывают друг друга и какие классы от чего наследуются».
- **Этап В: Контекст решений.**  
    Самое важное для Memory Bank — записывать _почему_ вы сделали именно так.  
    _Команда ИИ:_ «Запиши в граф, что мы выбрали FalkorDB вместо Neo4j, потому что нам нужна минимальная задержка при работе с локальным LLM».

4. Использование

Теперь, когда вы возвращаетесь к проекту через неделю, вы просто спрашиваете:

- _"Какие функции затронет изменение схемы в `models.py`?"_ (ИИ посмотрит связи в графе).
- _"Напомни логику авторизации, которую мы обсуждали вчера."_

Почему это лучше обычного поиска (RAG)?

Обычный поиск по коду найдет совпадение слов. **Graph MCP** понимает, что функция `A` вызывает функцию `B`, которая находится в другом файле, даже если они не содержат одинаковых ключевых слов.

**С какого модуля вашего проекта вы хотите начать индексацию?** Я могу составить запрос для ИИ, который правильно структурирует первые узлы графа.

```
И тут выбор, а если мне хочется и мощную аналитику и визуализацию взаимосвязей графа, и память по времени?

Но тут вопрос. У нас не живой чат где что то меняется у нас код опр версии. Если в новой версии что то удаляется или заменяется на другое то мы можем просто убрать это из графа знаний.
```

Если вы хотите **комбо** из аналитики, визуализации и отслеживания изменений, при этом работая с **локальным кодом**, ваш идеальный стек — это **Neo4j MCP**.

Вот почему для «статичного» кода с редкими изменениями это лучшее решение, и как закрыть ваши потребности:

Почему Neo4j — это «золотая середина»?

1. **Визуализация (Neo4j Bloom / Browser):** Вы сможете открыть браузер и буквально увидеть дерево вызовов вашего Python-проекта. Это на порядок нагляднее, чем текстовые ответы ИИ.
2. **Мощная аналитика:** Вы можете попросить ИИ: _«Найди все функции, которые зависят от `db_connector`, но не имеют обработки исключений»_. Neo4j выполнит это через Cypher-запрос (язык графов) быстрее и точнее любого другого инструмента.
3. **Память по времени (для версионности):** Хотя код кажется статичным, проект эволюционирует. В Neo4j вы можете добавлять свойство `version` или `timestamp` к узлам.

Как решать проблему удаления/замены кода?

Поскольку вы работаете с версиями кода, «память по времени» в графе реализуется двумя путями:

- **Полная синхронизация (Overwrite):** При масштабном рефакторинге вы даете ИИ команду: _«Очисти ветку графа для модуля X и просканируй его заново»_. Это гарантирует, что в «банке памяти» нет «призраков» удаленного кода.
- **Мягкое удаление (Soft Delete):** Вместо удаления узла, ИИ помечает его как `deprecated` или `removed_in_v2`. Это критически важно, если вы хотите спросить: _«Почему мы удалили тот класс месяц назад?»_.

---

Как это реализовать практически?

Я рекомендую использовать **Neo4j** вместе с плагином **APOC**, который позволяет делать практически всё.

Шаг 1: Запуск (Local & Free)

Запустите Neo4j локально через Docker. Мы добавим плагин APOC для расширенных возможностей:

bash

```
docker run \
    -p 7474:7474 -p 7687:7687 \
    --name neo4j-mcp \
    -e NEO4J_AUTH=neo4j/password123 \
    -e NEO4J_PLUGINS='["apoc"]' \
    neo4j:latest
```

Используйте код с осторожностью.

Шаг 2: Конфигурация MCP

Добавьте сервер в конфиг (например, используя официальный `mcp-server-neo4j` или его аналоги):

json

```
{
  "mcpServers": {
    "neo4j": {
      "command": "npx",
      "args": ["-y", "@modelcontextprotocol/server-neo4j"],
      "env": {
        "NEO4J_URI": "bolt://localhost:7687",
        "NEO4J_USER": "neo4j",
        "NEO4J_PASSWORD": "password123"
      }
    }
  }
}
```

Используйте код с осторожностью.

Шаг 3: Стратегия построения банка памяти

Чтобы не просто «хранить текст», а иметь **аналитику**, просите ИИ строить граф по схеме:

- **Узлы:** `File`, `Class`, `Function`, `Variable`, `Requirement`.
- **Связи:** `DEFINES`, `CALLS`, `IMPORTS`, `IMPLEMENTS`.

**Пример команды для ИИ:**

> "Просканируй `auth.py`. Создай узлы для каждой функции. Если функция `A` вызывает функцию `B`, создай связь `CALLS`. Если функция описана в документации `API.md`, свяжи её с узлом документации связью `DESCRIBED_IN`."

---

Итог:

Если вам нужна **визуальная карта** вашего проекта и возможность делать **сложные запросы** (например, поиск "бутылочного горлышка" в архитектуре), ставьте **Neo4j**. Это превратит ваш memory bank из простого хранилища в полноценный интерактивный чертеж проекта.

Хотите, я составлю для вас Cypher-запрос, который покажет все связи между вашими Python-файлами в интерфейсе Neo4j после того, как вы их проиндексируете?

Когда вы запускаете LLM-агент (в Claude Desktop, Cursor или через кастомный скрипт), он **не читает весь граф целиком**. Это было бы слишком дорого по токенам и бессмысленно.

Вместо этого общение происходит через **динамический поиск по требованию**:

1. Регистрация инструментов (Handshake)

При запуске агент опрашивает MCP-сервер: «Какие инструменты у тебя есть?». Neo4j MCP отвечает:

- `read_query`: выполнить любой Cypher-запрос.
- `get_node_details`: получить информацию о конкретном классе или функции.
- `search_nodes`: найти узлы по ключевым словам.

2. Поиск «входной точки» (Entry Point)

Когда вы задаете вопрос (например: _«Как работает загрузка файлов?»_), агент сначала ищет зацепки:

- Он вызывает `search_nodes(query="загрузка файлов")`.
- Граф возвращает ему узлы: файл `uploader.py`, класс `FileManager` и функцию `save_to_s3`.

3. Распутывание связей (Traversal)

Получив «входные точки», агент начинает **«идти по ребрам»**:

- Он видит связь: `save_to_s3` —(CALLS)→ `get_aws_credentials`.
- Он делает второй запрос к MCP: «Дай мне код функции `get_aws_credentials`, так как она вызывается в процессе».
- Так агент восстанавливает контекст, не загружая в память лишние 90% кода, которые не относятся к делу.

4. Использование графа как «Внешней памяти»

Если вы просите: «Объясни архитектуру проекта», агент выполнит аналитический запрос:

1. **Cypher-запрос:** `MATCH (f:File)-[:CONTAINS]->(c:Class) RETURN f.name, c.name`
2. **Результат:** Список всех файлов и классов.
3. **Ответ:** На основе этой структуры он строит объяснение.

Важный нюанс: Индексация

Чтобы агент мог «читать» проект, вы должны один раз прогнать его по коду.

- **Вы:** «Используй Neo4j MCP, чтобы проиндексировать папку `/src`. Выдели классы и зависимости».
- **Агент:** Создает сотни узлов и связей.
- **Результат:** Теперь база наполнена, и при каждом _следующем_ запуске агент будет «знать» о проекте всё, просто делая секундные запросы к локальному Neo4j.

Резюме

Агент читает граф **итеративно**. Он похож на детектива: сначала находит улику (узел), а потом идет по ниточкам (связям) к другим уликам, пока картина не сложится.

Хотите пример "системного промпта", который заставит агента активнее использовать граф при анализе вашего кода?

Именно в этом **главное преимущество** Graph MCP перед обычным RAG.

В стандартном RAG файл просто режется на куски (chunks) по 500–1000 знаков. Если функция `A` находится в начале файла, а функция `B`, которую она вызывает, — в конце, RAG может их «разлучить» и потерять связь.

Как это делает Graph MCP (на примере вашего Python-кода):

1. **Гранулярность (Атомарность):**  
    При индексации через Neo4j/FalkorDB каждый узел — это не «кусок текста», а **логическая единица**:
    - Узел типа `Function` (содержит только код одной функции).
    - Узел типа `Class` (содержит описание и список методов).
    - Узел типа `Docstring`.
2. **Точечное чтение:**  
    Если вы спрашиваете: _"Что делает метод `process_data`?"_, агент:
    - Не читает весь файл `models.py` на 2000 строк.
    - Он делает запрос: `MATCH (f:Function {name: "process_data"}) RETURN f.code`.
    - Получает **только 15 строк кода** этой конкретной функции.
3. **Контекстный прыжок (Traversal):**  
    Если внутри `process_data` есть вызов `validate_schema()`, который лежит в другом файле, агент видит связь `(process_data)-[:CALLS]->(validate_schema)`.
    - **Без графа:** Агенту пришлось бы искать `validate_schema` поиском по всей базе.
    - **С графом:** Он мгновенно запрашивает код связанного узла. Это экономит 80-90% «шумного» контекста, который обычно забивает память LLM в RAG.

Почему это критично для Python?

- **Циклические зависимости:** Граф их видит, RAG — нет.
- **Наследование:** Агент может мгновенно подняться по дереву классов: `MATCH (c:Class {name: "MyModel"})-[:INHERITS_FROM]->(parent) RETURN parent.code`.
- **Чистота контекста:** LLM получает только то, что относится к делу. Чем меньше лишнего кода в контексте, тем меньше ИИ «галлюцинирует» и тем точнее пишет код.

Как «приучить» агента к такому поведению?

Вам нужно использовать **индексатор**, который умеет парсить код в граф (Abstract Syntax Tree -> Graph). Большинство MCP-серверов для Neo4j имеют встроенные инструменты для этого.

**Хотите, я покажу, как выглядит структура (схема) такого графа для типичного Python-класса?** Это поможет вам понять, какие связи «просить» ИИ создавать при индексации.

Для Python-проекта схема графа в **Neo4j** должна отражать логику кода, а не просто текст. Вот как это выглядит структурно и как это видит агент:

Схема графа (Lego-кирпичики вашего проекта)

|Узел (Node)|Что содержит|Связь (Relationship)|К чему ведет|
|---|---|---|---|
|**File**|Путь, версия|`CONTAINS`|Классы и функции внутри|
|**Class**|Имя, docstring|`INHERITS_FROM`|Родительский класс|
|**Function**|**Чистый код**|`CALLS`|Другая функция|
|**Variable**|Тип, значение|`DEFINED_IN`|Область видимости|
|**Doc**|Техзадание/README|`IMPLEMENTS`|Функция или Класс|

Визуальный пример связи

Представьте файл `services/auth.py`, где класс `UserAuth` наследуется от `BaseService` и вызывает метод `db.connect()`.  
**В графе это будет цепочка:**  
`[BaseService] <--(:INHERITS)-- [UserAuth] --(:CALLS)--> [db.connect]`

---

Как агент работает с этим "Банком Памяти"

Когда вы просите: _"Добавь логирование в метод авторизации"_, агент делает следующие шаги через MCP:

1. **Запрос структуры:**  
    `MATCH (c:Class {name: "UserAuth"})-[:CONTAINS]->(f:Function) RETURN f.name`  
    _Агент видит список всех методов класса, не открывая файл._
2. **Чтение конкретики:**  
    `MATCH (f:Function {name: "login"}) RETURN f.code, f.docstring`  
    _Агент получает только 20 строк кода метода `login`, а не весь `auth.py` на 500 строк._
3. **Проверка зависимостей:**  
    `MATCH (f:Function {name: "login"})-[:CALLS]->(dep) RETURN dep.name, dep.file`  
    _Агент проверяет, не сломает ли логгер что-то еще._

Главные "фишки" такого подхода:

- **Экономия токенов:** Вместо 100 000 токенов (весь проект) агент потребляет 2 000 (только нужные узлы).
- **Точность рефакторинга:** Агент видит все места, где вызывается функция, благодаря связи `[:CALLS]`. Вы не забудете обновить код в другом конце проекта.
- **Локальная визуализация:** Вы можете открыть **Neo4j Browser**, ввести `MATCH (n) RETURN n`, и увидеть "созвездие" вашего кода, где самые важные функции будут в центре (у них больше всего связей).

С чего начать реализацию?

Для автоматического создания такого графа из Python-кода лучше всего использовать связку **Neo4j MCP** + скрипт-индексатор на базе библиотеки `ast` (Abstract Syntax Tree).

**Хотите, я напишу для вас Python-скрипт, который просканирует вашу папку с кодом и автоматически создаст эти узлы и связи в локальном Neo4j?** Это будет ваш первый шаг к созданию автономного Memory Bank.

Документацию в графе не стоит хранить одним огромным куском текста. Чтобы ИИ мог эффективно связывать её с кодом, используйте стратегию **«Атомарных знаний»**.

Вот лучшая структура для расположения документации в вашем Memory Bank:

1. Типы узлов для документации

Разбейте файлы (Markdown, Wiki, Notion) на следующие логические единицы:

- **`Requirement` (Требование):** Конкретная бизнес-задача или фича.
- **`LogicBlock` (Алгоритм):** Описание того, как именно должна работать функция (без кода).
- **`Terminology` (Глоссарий):** Определения терминов, чтобы ИИ не путал «User» (клиент) и «User» (объект в БД).
- **`Decision` (Архитектурное решение):** Почему вы выбрали именно этот подход (ADR — Architecture Decision Records).

2. Ключевые связи (Relationships)

Самое ценное в графе — это «мостики» между текстом и кодом:

- `[Requirement] --(:IMPLEMENTED_BY)--> [Function]` (Связь задачи с кодом).
- `[LogicBlock] --(:DESCRIBES)--> [Class]` (Связь описания с архитектурой).
- `[Decision] --(:AFFECTS)--> [Module]` (Почему этот модуль написан именно так).

3. Как это организовать (Best Practice)

Вместо того чтобы копировать весь текст документа в атрибут узла, делайте так:

1. **Заголовок и Суть:** В самом узле графа храните краткое резюме (Summary).
2. **Chunking:** Если раздел документации большой, разбейте его на подразделы (узлы), связанные между собой через `(:NEXT_SECTION)`.
3. **Метаданные:** Указывайте `source_file` и `line_number`, чтобы агент мог при необходимости открыть оригинальный файл.

---

Практический пример:

Вы описываете фичу «Авторизация через JWT».

- **Узел документации:** `{id: "Req_1", type: "Requirement", text: "Система должна использовать JWT для сессий"}`.
- **Узел кода:** `{id: "Func_42", name: "create_access_token", code: "..."}`.
- **Связь в графе:** `(Req_1)-[:SPECIFIES]->(Func_42)`.

**Что это дает?**  
Когда вы скажете агенту: _"Измени способ генерации токенов"_, он не просто найдет код, но и сразу увидит узел **Requirement**, прочитает требования и скажет: _"В документации указано, что мы должны использовать алгоритм HS256, мне придерживаться этого правила?"_.

Как наполнять?

Вы можете попросить ИИ:

> «Прочитай `docs/architecture.md`, разбей его на ключевые требования и свяжи каждое требование с соответствующими классами в графе, которые мы проиндексировали ранее».

Хотите, я дополню Python-скрипт (о котором говорил ранее), чтобы он умел парсить Markdown-файлы и связывать их с вашими функциями в Neo4j?

# MCP для roam

* https://github.com/2b3pro/roam-research-mcp